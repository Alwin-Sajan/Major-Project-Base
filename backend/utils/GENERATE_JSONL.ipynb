{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7db27cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5139dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Species marker (robust)\n",
    "SPECIES_PATTERN = re.compile(\n",
    "    r\"^\\s*species\\s*name\\s*[:\\-]\\s*(.+)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "#2) Robust heading detection (bold OR heading style OR \"Label:\" pattern)\n",
    "LABEL_HEADING_PATTERN = re.compile(\n",
    "    r\"^[A-Za-z][A-Za-z0-9\\s\\-/]{1,60}:\\s*$\"  # e.g. \"Body:\" \"Prostomium:\" \"Antennae and cirri:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97825fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_species_marker(text: str) -> bool:\n",
    "    return bool(SPECIES_PATTERN.match((text or \"\").strip()))\n",
    "\n",
    "def extract_species_name(text: str) -> str:\n",
    "    m = SPECIES_PATTERN.match((text or \"\").strip())\n",
    "    return m.group(1).strip() if m else \"UNKNOWN\"\n",
    "\n",
    "def extract_genus(species_name: str) -> Optional[str]:\n",
    "    if not species_name:\n",
    "        return None\n",
    "    parts = species_name.strip().split()\n",
    "    return parts[0] if parts else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a94110df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_is_bold(run) -> bool:\n",
    "    # run.bold can be True/False/None\n",
    "    # run.font.bold sometimes carries inherited bold\n",
    "    return bool(run.bold) or bool(getattr(run.font, \"bold\", False))\n",
    "\n",
    "def is_heading_style(p) -> bool:\n",
    "    style_name = (p.style.name or \"\").lower() if p.style else \"\"\n",
    "    return \"heading\" in style_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b131e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_boldish_paragraph(p, bold_ratio_threshold: float = 0.35) -> bool:\n",
    "    \"\"\"\n",
    "    Bold detector that works better on real docx:\n",
    "    - considers run.bold OR run.font.bold\n",
    "    - uses a lower default threshold\n",
    "    \"\"\"\n",
    "    text = (p.text or \"\").strip()\n",
    "    if not text:\n",
    "        return False\n",
    "\n",
    "    runs = [r for r in p.runs if (r.text or \"\").strip()]\n",
    "    if not runs:\n",
    "        return False\n",
    "\n",
    "    total_chars = sum(len(r.text.strip()) for r in runs)\n",
    "    if total_chars == 0:\n",
    "        return False\n",
    "\n",
    "    bold_chars = sum(len(r.text.strip()) for r in runs if run_is_bold(r))\n",
    "    return (bold_chars / total_chars) >= bold_ratio_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9e9519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_label_heading(text: str) -> bool:\n",
    "    \"\"\"\n",
    "    Catch headings that are not bold in docx after merge:\n",
    "    'Body:' 'Prostomium:' etc.\n",
    "    \"\"\"\n",
    "    t = (text or \"\").strip()\n",
    "    if not t:\n",
    "        return False\n",
    "    # keep it short (avoid treating long sentences as headings)\n",
    "    if len(t) > 80:\n",
    "        return False\n",
    "    return bool(LABEL_HEADING_PATTERN.match(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a490a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_general_heading_paragraph(p, bold_ratio_threshold: float = 0.35) -> bool:\n",
    "    \"\"\"\n",
    "    A paragraph is a general-heading boundary if:\n",
    "    - Heading style, OR\n",
    "    - Boldish, OR\n",
    "    - Looks like \"Label:\" (fallback)\n",
    "    But not if it is \"Species Name:\"\n",
    "    \"\"\"\n",
    "    text = (p.text or \"\").strip()\n",
    "    if not text:\n",
    "        return False\n",
    "    if is_species_marker(text):\n",
    "        return False\n",
    "\n",
    "    return (\n",
    "        is_heading_style(p)\n",
    "        or is_boldish_paragraph(p, bold_ratio_threshold=bold_ratio_threshold)\n",
    "        or looks_like_label_heading(text)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f87b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Combined chunker\n",
    "def chunk_merged_docx(\n",
    "    docx_path: str,\n",
    "    authority: str = \"CMLRE\",\n",
    "    year: int = 2025,\n",
    "    bold_ratio_threshold: float = 0.35,\n",
    "    include_heading_in_general_text: bool = True,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    For ONE merged docx:\n",
    "    - Taxonomic chunk per species block (Species Name -> next Species Name)\n",
    "    - General info chunks within each species block (heading/bold/label -> next heading/bold/label)\n",
    "    - Also captures general-info chunks that appear before the first species (species_name=None)\n",
    "    \"\"\"\n",
    "    doc = Document(docx_path)\n",
    "    paras = list(doc.paragraphs)\n",
    "    source_file = Path(docx_path).name\n",
    "\n",
    "    # Find all species marker indices\n",
    "    species_starts = [i for i, p in enumerate(paras) if is_species_marker((p.text or \"\").strip())]\n",
    "\n",
    "    chunks: List[Dict] = []\n",
    "\n",
    "    # ---------- Helper: build general chunks within a range ----------\n",
    "    def add_general_chunks_in_range(start_i: int, end_i: int, species_name: Optional[str], genus: Optional[str]):\n",
    "        # heading boundaries within [start_i, end_i]\n",
    "        headings = []\n",
    "        for i in range(start_i, end_i + 1):\n",
    "            txt = (paras[i].text or \"\").strip()\n",
    "            if not txt:\n",
    "                continue\n",
    "            if is_general_heading_paragraph(paras[i], bold_ratio_threshold=bold_ratio_threshold):\n",
    "                headings.append(i)\n",
    "\n",
    "        for k, h_start in enumerate(headings):\n",
    "            h_end = (headings[k + 1] - 1) if (k + 1 < len(headings)) else end_i\n",
    "            title = (paras[h_start].text or \"\").strip()\n",
    "\n",
    "            lines = []\n",
    "            for j in range(h_start, h_end + 1):\n",
    "                t = (paras[j].text or \"\").strip()\n",
    "                if not t:\n",
    "                    continue\n",
    "                if j == h_start:\n",
    "                    if include_heading_in_general_text:\n",
    "                        lines.append(t)\n",
    "                else:\n",
    "                    lines.append(t)\n",
    "\n",
    "            text_block = \"\\n\".join(lines).strip()\n",
    "            if text_block:\n",
    "                chunks.append({\n",
    "                    \"chunk_type\": \"general\",\n",
    "                    \"species_name\": species_name,\n",
    "                    \"genus\": genus,\n",
    "                    \"authority\": authority,\n",
    "                    \"year\": year,\n",
    "                    \"section\": \"general information\",\n",
    "                    \"title\": title,\n",
    "                    \"text\": text_block,\n",
    "                    \"source_file\": source_file,\n",
    "                    \"paragraph_span\": [h_start, h_end],\n",
    "                })\n",
    "\n",
    "    # ---------- (A) General info BEFORE first species ----------\n",
    "    if species_starts:\n",
    "        pre_end = species_starts[0] - 1\n",
    "        if pre_end >= 0:\n",
    "            add_general_chunks_in_range(0, pre_end, species_name=None, genus=None)\n",
    "\n",
    "    # ---------- (B) Species blocks ----------\n",
    "    for idx, s_start in enumerate(species_starts):\n",
    "        s_end = (species_starts[idx + 1] - 1) if (idx + 1 < len(species_starts)) else (len(paras) - 1)\n",
    "\n",
    "        marker_text = (paras[s_start].text or \"\").strip()\n",
    "        species_name = extract_species_name(marker_text)\n",
    "        genus = extract_genus(species_name)\n",
    "\n",
    "        # Taxonomic chunk: whole species block\n",
    "        block_lines = []\n",
    "        for j in range(s_start, s_end + 1):\n",
    "            t = (paras[j].text or \"\").strip()\n",
    "            if t:\n",
    "                block_lines.append(t)\n",
    "\n",
    "        tax_text = \"\\n\".join(block_lines).strip()\n",
    "        chunks.append({\n",
    "            \"chunk_type\": \"taxonomic\",\n",
    "            \"species_name\": species_name,\n",
    "            \"genus\": genus,\n",
    "            \"authority\": authority,\n",
    "            \"year\": year,\n",
    "            \"section\": \"taxonomic information\",\n",
    "            \"text\": tax_text,\n",
    "            \"source_file\": source_file,\n",
    "            \"paragraph_span\": [s_start, s_end],\n",
    "        })\n",
    "\n",
    "        # General chunks inside this species block (usually after Species Name line)\n",
    "        if s_start + 1 <= s_end:\n",
    "            add_general_chunks_in_range(s_start + 1, s_end, species_name=species_name, genus=genus)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628dd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_jsonl(chunks: List[Dict], out_path: str) -> None:\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ch in chunks:\n",
    "            f.write(json.dumps(ch, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    docx_file = \"/home/abk/abk/projects/Major-project-basic-ui/backend/taxonomy_data/taxonomy_data.docx\" \n",
    "    out_file = \"/home/abk/abk/projects/Major-project-basic-ui/backend/taxonomy_data/merged_taxonomic_chunks.jsonl\"\n",
    "\n",
    "    chunks = chunk_merged_docx(\n",
    "        docx_path=docx_file,\n",
    "        authority=\"CMLRE\",\n",
    "        year=2025,\n",
    "        bold_ratio_threshold=0.35,  # try 0.25 if still missing headings\n",
    "        include_heading_in_general_text=True,\n",
    "    )\n",
    "\n",
    "    tax = sum(1 for c in chunks if c[\"chunk_type\"] == \"taxonomic\")\n",
    "    gen = sum(1 for c in chunks if c[\"chunk_type\"] == \"general\")\n",
    "\n",
    "    print(\"Total chunks:\", len(chunks))\n",
    "    print(\"Taxonomic chunks:\", tax)\n",
    "    print(\"General chunks:\", gen)\n",
    "\n",
    "    save_jsonl(chunks, out_file)\n",
    "    print(\"Saved:\", out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
